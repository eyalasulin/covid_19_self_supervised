{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import statistics\n",
    "%config Completer.use_jedi = False  # help with autocompletions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mode = False\n",
    "batch_size = 16\n",
    "pre_encode_size = 1024\n",
    "projection_units = 128\n",
    "EPOCHS = 1  # can be also 40-45  # try also 0 and 1.\n",
    "model_name = f'model_{batch_size}_{EPOCHS}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-Ej8T_uOpPr",
    "outputId": "80525661-06bd-4445-b68b-4c22fb2fb96c"
   },
   "outputs": [],
   "source": [
    "\n",
    "class batch_generator:\n",
    "    def __init__(self, batch_size=batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.data = []\n",
    "        self.batch = []\n",
    "        self.image_size = [160, 160]\n",
    "        self.crop_size = [120, 120, 3]\n",
    "    def create_img_list(self):\n",
    "        self.luna_dir = './train/'\n",
    "        self.img_list = []\n",
    "        for img in os.listdir(self.luna_dir):\n",
    "            full_path = os.path.join(self.luna_dir, img)\n",
    "            self.img_list.append(full_path)\n",
    "\n",
    "    def load_luna(self):\n",
    "        self.samples = []\n",
    "        i = 0\n",
    "        for img in self.img_list:\n",
    "            i +=1\n",
    "            if dev_mode:\n",
    "                if i > 100:\n",
    "                    break\n",
    "            loaded_img = tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(img))\n",
    "            self.samples.append(loaded_img)\n",
    "            # i need to use the real image and one augmented img and than add batch_size -2 augmented images\n",
    "            # from different source images\n",
    "    \n",
    "    def gen_batch_2(self):\n",
    "        num_of_batches = len(self.samples)//self.batch_size  # e.g 100//15 = 6\n",
    "        epoch_mv = []\n",
    "\n",
    "        for i in range(num_of_batches):  # e.g: 6\n",
    "            batch_1 = []\n",
    "            batch_2 = []\n",
    "            for j in range(self.batch_size):  #15\n",
    "                batch_1.append(self.get_tensor_aug_img(self.samples[i]))\n",
    "                batch_2.append(self.get_tensor_aug_img(self.samples[i]))\n",
    "            mv_batch = [batch_1, batch_2]\n",
    "            mv_batch = np.array(mv_batch)\n",
    "\n",
    "            epoch_mv.append(mv_batch)\n",
    "            \n",
    "        return(epoch_mv)\n",
    "    \n",
    "\n",
    "    def get_tensor_aug_img(self, img):\n",
    "        source_img = tf.image.resize(img, self.image_size)\n",
    "        self.batch.append(tf.convert_to_tensor(source_img)) \n",
    "        aug_img = tf.image.random_flip_left_right(tf.image.random_crop(value=img, size= self.crop_size))\n",
    "        aug_img = tf.image.resize(aug_img, self.image_size)\n",
    "        return aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7y0I07QSnCI",
    "outputId": "d9ac894d-b658-4e88-e524-16e7ae2fac09"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Generate batches\n",
    "gen = batch_generator()\n",
    "gen.create_img_list()\n",
    "gen.load_luna()\n",
    "epoch = gen.gen_batch_2()  # 1000//batch*batch*2*160*160*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 160, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = (160, 160)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "IMG_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DJYuCJmcRp0D"
   },
   "outputs": [],
   "source": [
    "# Creating model\n",
    "self_trans_model = create_contrastive_model(pre_encode_size, projection_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f729c3b8690> <class 'tensorflow.python.keras.engine.input_layer.InputLayer'>\n",
      "True <tensorflow.python.keras.layers.preprocessing.normalization.Normalization object at 0x7f729c321f90> <class 'tensorflow.python.keras.layers.preprocessing.normalization.Normalization'>\n",
      "False <tensorflow.python.keras.engine.functional.Functional object at 0x7f729c34d790> <class 'tensorflow.python.keras.engine.functional.Functional'>\n",
      "True <tensorflow.python.keras.layers.core.Flatten object at 0x7f729c339dd0> <class 'tensorflow.python.keras.layers.core.Flatten'>\n",
      "True <tensorflow.python.keras.layers.core.Dense object at 0x7f729c22ee50> <class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "True <tensorflow.python.keras.layers.core.TFOpLambda object at 0x7f729c355e90> <class 'tensorflow.python.keras.layers.core.TFOpLambda'>\n",
      "True <tensorflow.python.keras.layers.core.Dense object at 0x7f729c232f90> <class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "True <tensorflow.python.keras.layers.core.TFOpLambda object at 0x7f729c23fd90> <class 'tensorflow.python.keras.layers.core.TFOpLambda'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in self_trans_model.layers:\n",
    "    print(layer.trainable, layer, type(layer))\n",
    "\n",
    "self_trans_model.layers[2].trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f729c3b8690>,\n",
       " <tensorflow.python.keras.layers.preprocessing.normalization.Normalization at 0x7f729c321f90>,\n",
       " <tensorflow.python.keras.engine.functional.Functional at 0x7f729c34d790>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x7f729c339dd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f729c22ee50>,\n",
       " <tensorflow.python.keras.layers.core.TFOpLambda at 0x7f729c355e90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f729c232f90>,\n",
       " <tensorflow.python.keras.layers.core.TFOpLambda at 0x7f729c23fd90>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_trans_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmpHZwj9Q5mE",
    "outputId": "84e3d084-a809-48d8-f005-b8e40f011ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train started:\n",
      "starting epoch\n",
      "43.33409\n",
      "43.528687\n",
      "43.349667\n",
      "43.334602\n",
      "43.36657\n",
      "43.34536\n",
      "43.347824\n",
      "Epoch Num 0, Avrg Loss: 43.365753173828125\n",
      "0\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "# Track Results\n",
    "train_loss_results = []\n",
    "train_accuracy_results =[]\n",
    "\n",
    "# Loop variables\n",
    "\n",
    "# Training loop\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "print (\"Train started:\")\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    epoch_loss = []\n",
    "    print(\"starting epoch\")\n",
    "#     epoch = gen.gen_batch_2()\n",
    "    for idx in range(len(epoch)):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits_1 = self_trans_model(epoch[idx][0],training =True)\n",
    "            logits_2 = self_trans_model(epoch[idx][1],training =True)\n",
    "            mvb_loss = bmv_loss(logits_1, logits_2, 0.1)\n",
    "            grads = tape.gradient(mvb_loss, self_trans_model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, self_trans_model.trainable_weights))\n",
    "        if not idx% 10:\n",
    "            print(mvb_loss.numpy())\n",
    "\n",
    "        epoch_loss.append(mvb_loss.numpy())\n",
    "    avrg_loss = statistics.mean(epoch_loss)\n",
    "    print(f\"Epoch Num {e}, Avrg Loss: {avrg_loss}\")\n",
    "    print(gc.collect())\n",
    "print(\"success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "self_trans_model.save(model_name)\n",
    "\n",
    "loaded = tf.keras.models.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_16_1.h5'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}